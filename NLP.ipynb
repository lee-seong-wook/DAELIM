{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsaixBCterTrn6acMxO4kD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee-seong-wook/DAELIM/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rbk9xvHYUpU",
        "outputId": "8af00ddf-dff2-410c-a5f3-0f806c363996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['해보지', '않으면', '해낼', '수', '없다']\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "text = '해보지 않으면 해낼 수 없다'\n",
        "result = text_to_word_sequence(text)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "docs = ['먼저 텍스트의 각 단어를 나누어 토큰화합니다',\n",
        "        '텍스트의 단어로 토큰화해야 딥러닝에서 인식합니다',\n",
        "        '토큰화한 결과는 딥러닝에서 사용할 수 있습니다']\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "print(token.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJZyGKZkaLNH",
        "outputId": "64469d60-5f2b-49a7-9a09-7dc9c52fa3c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식합니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token.document_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5x9cJqmbMXL",
        "outputId": "3f9c0900-8f46-4aa5-f2a1-02819f19f22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token.word_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H2roRdhbpEb",
        "outputId": "e9aa8b2b-8802-4374-dde9-b2c294ae6444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'나누어': 1, '단어를': 1, '먼저': 1, '토큰화해야': 2, '인식합니다': 2, '딥러닝에서': 3, '단어로': 2, '토큰화합니다': 1, '각': 1, '텍스트의': 2, '결과는': 1, '수': 1, '있습니다': 1, '토큰화한': 1, '사용할': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"오랫동안 꿈꾸는 이는 그 꿈을 닮아간다\"\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts([text])\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ipw8fjib60K",
        "outputId": "9495327d-8f15-4b6a-a064-78595e8614bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'오랫동안': 1, '꿈꾸는': 2, '이는': 3, '그': 4, '꿈을': 5, '닮아간다': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = token.texts_to_sequences([text])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RILs1tmZfcez",
        "outputId": "82de9784-b91e-4b82-82e3-950c19363eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4, 5, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = '해보지 않으면 해낼 수 없다'\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "\n",
        "\n",
        "x = tokenizer.texts_to_sequences([text])\n",
        "\n",
        "\n",
        "word_size = len(tokenizer.word_index) + 1\n",
        "x = to_categorical(x, num_classes=word_size)\n",
        "\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coCk-F8deV-3",
        "outputId": "460a2218-5fdd-4cf8-8a2a-7c2338a06652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(16, 4))"
      ],
      "metadata": {
        "id": "0Nq9W_kOfaEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "docs = ['너무 재밌네요','최고에요','참 잘 만든 영화예요','추천하고 싶은 영화입니다.','한번 더 보고싶네요','글쎄요','별로예요','생각보다 지루하네요','연기가 어색해요','재미없네요']\n",
        "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XrMCX_HkTv6",
        "outputId": "f45d26a5-a439-495f-b0d8-f5a687cdae82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'너무': 1, '재밌네요': 2, '최고에요': 3, '참': 4, '잘': 5, '만든': 6, '영화예요': 7, '추천하고': 8, '싶은': 9, '영화입니다': 10, '한번': 11, '더': 12, '보고싶네요': 13, '글쎄요': 14, '별로예요': 15, '생각보다': 16, '지루하네요': 17, '연기가': 18, '어색해요': 19, '재미없네요': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = token.texts_to_sequences(docs)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltgEi83ek01-",
        "outputId": "b306c4d1-83cf-4947-ca9a-ffc5662e4891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [3], [4, 5, 6, 7], [8, 9, 10], [11, 12, 13], [14], [15], [16, 17], [18, 19], [20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "padded_x = pad_sequences(x,4) #(x, maxlen =4)도 가능함\n",
        "\n",
        "print(padded_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHWKtxLSlohe",
        "outputId": "06be1503-246a-45d6-a296-27cd18d03175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  1  2]\n",
            " [ 0  0  0  3]\n",
            " [ 4  5  6  7]\n",
            " [ 0  8  9 10]\n",
            " [ 0 11 12 13]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 15]\n",
            " [ 0  0 16 17]\n",
            " [ 0  0 18 19]\n",
            " [ 0  0  0 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_size = len(token.word_index)+1\n"
      ],
      "metadata": {
        "id": "gDMBIOKDmrP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Embedding(word_size, 8, input_length=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dppvZl2TnFKO",
        "outputId": "1060f747-6a2c-4463-a6b5-610b21de7bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7ddda57ad900>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "docs = ['너무 재밌네요', '최고에요', '참 잘 만든 영화예요', '추천하고 싶은 영화입니다.', '한번 더 보고싶네요', '글쎄요', '별로예요', '생각보다 지루하네요', '연기가 어색해요', '재미없네요']\n",
        "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(docs)\n",
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "\n",
        "max_sequence_length = 4\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "word_size = len(word_index) + 1\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_size, 8, input_length=max_sequence_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(padded_sequences, labels, epochs=10)\n",
        "\n",
        "\n",
        "accuracy = model.evaluate(padded_sequences, labels)[1]\n",
        "print(\"\\nAccuracy: %.4f\" % accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwh2S63in-9u",
        "outputId": "9b5bfcb4-773b-4a14-f057-82aa0ddccc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.6906 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6889 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6856 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.7000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.7000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.7000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6756 - accuracy: 0.7000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.6740 - accuracy: 0.9000\n",
            "\n",
            "Accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "(X_train, Y_train),(X_test, Y_test) = reuters.load_data(num_words=1000, test_split=0.2) #num_words는 빈도수를 지정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZOhBQK8o48i",
        "outputId": "30992a46-fae5-4d9f-bb5a-c8831c9474c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "category = np.max(Y_train) + 1\n",
        "print(category, '카테고리')\n",
        "print(len(X_train), '학습용 뉴스 기사')\n",
        "print(len(X_test), '테스트용 뉴스 기사')\n",
        "print(X_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1AVJ0REv3_J",
        "outputId": "302d0fa1-3cc7-4627-906e-25a9e9a899b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 카테고리\n",
            "8982 학습용 뉴스 기사\n",
            "2246 테스트용 뉴스 기사\n",
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=100)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=100)\n",
        "y_train = np_utils.to_categorical(Y_train)\n",
        "y_test = np_utils.to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "zqtX2aTZwqEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(1000, 100))\n",
        "model.add(LSTM(100, activation='tanh'))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=100, epochs=20, validation_data=(x_test, y_test))\n",
        "validation_data = (x_test, y_test)\n",
        "print(\"\\nTest Accuracy: %.4f\" % (model.evaluate(x_test, y_test)[1]))\n",
        "\n"
      ],
      "metadata": {
        "id": "z--h2gXryfuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(x_train, y_train),(x_test,y_test) = imdb.load_data(num_words=5000)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkZZPVRqz6Xf",
        "outputId": "3adc975e-3a65-4735-eb3b-ef4c7915f861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, MaxPooling1D, LSTM, Dense, Activation\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000,100))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv1D(64,5, padding='valid', activation='relu',strides=1))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(55))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udkFrvK13r3o",
        "outputId": "eb5a932f-12b1-404b-d8ee-cbccfef43931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 100)         500000    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, None, 100)         0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, None, 64)          32064     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, None, 64)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 55)                26400     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 56        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 558,520\n",
            "Trainable params: 558,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=100, epochs=5, validation_data=(x_test, y_test))\n",
        "print(\"\\n Test Accuracy:%4f\" % (model.evaluate(x_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4pocZiR4q_n",
        "outputId": "3a088cd0-4c65-4bfc-ef1e-831546d22e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "250/250 [==============================] - 46s 124ms/step - loss: 0.4567 - accuracy: 0.7693 - val_loss: 0.3373 - val_accuracy: 0.8516\n",
            "Epoch 2/5\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.2974 - accuracy: 0.8747 - val_loss: 0.3277 - val_accuracy: 0.8559\n",
            "Epoch 3/5\n",
            "250/250 [==============================] - 5s 22ms/step - loss: 0.2552 - accuracy: 0.8962 - val_loss: 0.3270 - val_accuracy: 0.8574\n",
            "Epoch 4/5\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.2210 - accuracy: 0.9127 - val_loss: 0.3393 - val_accuracy: 0.8545\n",
            "Epoch 5/5\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.1847 - accuracy: 0.9291 - val_loss: 0.3716 - val_accuracy: 0.8527\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.3716 - accuracy: 0.8527\n",
            "\n",
            " Test Accuracy:0.852680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_buh40e6b4_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}